---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-embed
  labels:
    app: vllm-embed
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-embed
  template:
    metadata:
      labels:
        app: vllm-embed
    spec:
      containers:
        - name: vllm-openai
          image: ghcr.io/theepicsaxguy/vllm-cpu:v0.11.0-cfc13f2
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh", "-c"]
          args:
            - >
              python3 -m vllm.entrypoints.openai.api_server
              --model Qwen/Qwen3-Embedding-0.6B
              --convert embed
              --port 8000
              --host 0.0.0.0
              --api-key $VLLM_API_KEY
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: app-vllm-embed-hf-token
                  key: HUGGING_FACE_HUB_TOKEN
            - name: VLLM_API_KEY
              valueFrom:
                secretKeyRef:
                  name: app-vllm-embed-api-key
                  key: VLLM_API_KEY
            - name: VLLM_CPU_KVCACHE_SPACE
              value: "2"
          ports:
            - name: http
              containerPort: 8000
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
          resources:
            requests:
              cpu: "2000m"
              memory: "2Gi"
            limits:
              cpu: "4000m"
              memory: "6Gi"
      volumes:
        - name: hf-cache
          persistentVolumeClaim:
            claimName: vllm-model-cache
