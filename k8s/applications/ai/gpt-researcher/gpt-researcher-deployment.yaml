apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpt-researcher
  namespace: gpt-researcher
  labels:
    app.kubernetes.io/name: gpt-researcher
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gpt-researcher
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gpt-researcher
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: gpt-researcher
          image: ghcr.io/assafelovic/gpt-researcher:pr-1608
          imagePullPolicy: IfNotPresent
          command: ["python", "main.py", "--config_path", "/usr/src/app/config.json"]
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: app-gpt-researcher-litellm-api-key
                  key: OPENAI_API_KEY
            - name: OPENAI_BASE_URL
              value: "https://litellm.peekoff.com"
            - name: TAVILY_API_KEY
              valueFrom:
                secretKeyRef:
                  name: gpt-researcher-secrets
                  key: TAVILY_API_KEY
            - name: LANGCHAIN_API_KEY
              valueFrom:
                secretKeyRef:
                  name: gpt-researcher-secrets
                  key: LANGCHAIN_API_KEY
            - name: LOGGING_LEVEL
              value: "INFO"
            # Environment variables take precedence over config.json for FastAPI requests
            - name: EMBEDDING
              value: "azure_openai:text-embedding-3-small"
            - name: FAST_LLM
              value: "azure:gpt-5-nano"
            - name: SMART_LLM
              value: "azure:gpt-5.2"
            - name: STRATEGIC_LLM
              value: "azure:gpt-5.2"
          ports:
            - containerPort: 8000
              name: http
          volumeMounts:
            - name: my-docs
              mountPath: /usr/src/app/my-docs
            - name: outputs
              mountPath: /usr/src/app/outputs
            - name: logs
              mountPath: /usr/src/app/logs
            - name: config
              mountPath: /usr/src/app/config.json
              subPath: config.json
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 15
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "2000m"
              memory: "2Gi"
      volumes:
        - name: my-docs
          persistentVolumeClaim:
            claimName: gpt-researcher-my-docs
        - name: outputs
          persistentVolumeClaim:
            claimName: gpt-researcher-outputs
        - name: logs
          persistentVolumeClaim:
            claimName: gpt-researcher-logs
        - name: config
          configMap:
            name: gpt-researcher-config
