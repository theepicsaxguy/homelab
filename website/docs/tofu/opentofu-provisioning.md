---
title: Provision the Talos Kubernetes cluster with opentofu
---

opentofu is utilized to define and provision the Kubernetes cluster. The chosen operating system for the cluster nodes
is Talos, which runs on Proxmox virtual machines. This methodology establishes an immutable, API-managed Kubernetes
environment.

## About the provisioning process

This section details the components and rationale for using opentofu and Talos to provision the Kubernetes cluster.

### Directory structure

The opentofu configuration is organized as follows:

- `/tofu/main.tf`: The main entrypoint that defines the Talos module and its node configurations.
- `/tofu/variables.tf`: Defines input variables used by the opentofu configuration.
- `/tofu/output.tf`: Specifies outputs generated by opentofu upon successful execution, such as the Kubeconfig file.
- `/tofu/providers.tf`: Contains configurations for the opentofu providers used (e.g., Proxmox, Talos).
- `/tofu/talos/`: A local opentofu module responsible for the creation and configuration of the Talos cluster.
  - `config.tf`: Generates Talos machine configurations and manages the cluster bootstrapping process.
  - `image.tf`: Handles the creation of Talos OS images and their download to the Proxmox environment.
  - `virtual-machines.tf`: Defines the Proxmox Virtual Machines (VMs) that will serve as cluster nodes.
  - `machine-config/`: Contains template files for generating Talos machine configurations.
  - `inline-manifests/`: Stores YAML files for core components like Cilium and CoreDNS, which are embedded into the
    Talos configuration during the bootstrap phase.
- `/tofu/upgrade-k8s.sh`: A utility script designed for upgrading the Kubernetes version on existing Talos nodes.
- `/tofu/data_disks.tf` (Commented Out): Represents a previous method for managing persistent disks. Currently, disks
  are attached directly to VMs as defined in `virtual-machines.tf`.

### Core components and design rationale

#### Proxmox provider

The `bpg/proxmox` opentofu provider is used to interact with the Proxmox VE hypervisor. This enables the declarative
definition of VMs, their allocated resources, and network settings.

:::info **Rationale for using opentofu for VMs:** Codifying the cluster's base infrastructure with opentofu allows for
repeatable, version-controlled, and automated deployments. This significantly simplifies the process of rebuilding or
scaling the cluster. :::

#### Talos provider and operating system

Talos Linux was selected as the operating system for Kubernetes nodes. Talos is a minimal, secure, and immutable OS
specifically designed for Kubernetes. It is managed entirely via an API, which aligns well with the declarative,
GitOps-centric management philosophy of this homelab. The `siderolabs/talos` provider assists in generating the
necessary configurations and bootstrapping the cluster.

:::info **Rationale for choosing Talos:**

- **Enhanced Security:** The minimal design of Talos reduces its attack surface.
- **Immutability:** OS upgrades are atomic, which minimizes configuration drift and enhances system reliability.
- **API-Driven Management:** All node configurations are applied via machine configuration files, which can be
  version-controlled and managed declaratively. :::

#### VM configuration (`/tofu/talos/virtual-machines.tf`)

This file defines each node in the Kubernetes cluster, including control plane nodes and worker nodes.

- **Node Definitions:** Node specifications are located in `/tofu/main.tf` within the `nodes` map of the
  `module "talos"` block. Each node definition includes parameters such as:

  - `host_node`: The Proxmox physical host where the VM will be provisioned.
  - `machine_type`: Designates the node's role as either `controlplane` or `worker`.
  - `ip`, `mac_address`, `vm_id`: Network and Proxmox-specific identification details.
  - `cpu`, `ram_dedicated`: CPU and RAM resources allocated to the VM.
  - `disks`: Defines any additional disks for the node, such as those used by Longhorn for persistent storage. These are
    attached directly to worker VMs for simplicity and direct access. The `size` is specified in gigabytes (e.g.,
    "180G").

- **Image Management (`/tofu/talos/image.tf`):**
  - Custom Talos OS images are built using the Talos Image Factory (`factory.talos.dev`). The schematic file,
    `/tofu/talos/image/schematic.yaml`, defines system extensions (e.g., `siderolabs/qemu-guest-agent`,
    `siderolabs/iscsi-tools`) that are incorporated into the OS image.
  - The `proxmox_virtual_environment_download_file` opentofu resource is responsible for downloading the generated image
    to the Proxmox environment for use in VM deployments. :::info **Rationale for custom images:** Including necessary
    tools or drivers directly within the immutable OS image simplifies node setup and ensures consistency across all
    nodes. :::

#### Machine configuration (`/tofu/talos/config.tf` & `/tofu/talos/machine-config/`)

Talos nodes are configured using YAML files. opentofu generates these files from templates.

- **`talos_machine_configuration` resource:** This resource generates the specific machine configuration for each node.
- **Templates (`control-plane.yaml.tftpl`, `worker.yaml.tftpl`):**
  - These templates are used to inject node-specific settings (such as hostname and IP address) and cluster-wide
    settings (like cluster name, API endpoint, and Virtual IP (VIP)).
  - **Embedding Core Manifests:** Installation manifests for essential components like Cilium (Container Network
    Interface - CNI) and CoreDNS are embedded directly into the control plane machine configurations using Talos's
    `inlineManifests` feature. :::info **Rationale for embedding core manifests:** This approach ensures that the CNI
    and DNS services are available as soon as the cluster bootstraps. This allows the cluster to become functional
    without requiring external post-provisioning steps. For Cilium, its `values.yaml` content is embedded into a
    ConfigMap within the Talos configuration; the Cilium installation job (also an inline manifest) then utilizes this
    ConfigMap. This practice keeps the Cilium configuration version-controlled alongside the cluster infrastructure. :::
  - `certSANs`: The control plane VIP and individual node IPs are included in the Talos API server certificate's Subject
    Alternative Names (SANs) to ensure valid TLS communication.
  - `kubelet.extraMounts`: For worker nodes that utilize Longhorn for storage, the specified `mountpoint` (e.g.,
    `/var/lib/longhorn`) is configured as a bind-mount and shared (`rshared`). This configuration is necessary for
    Longhorn to correctly manage storage on those paths.

### Bootstrapping process overview

1. opentofu interprets the `.tf` files and defines the VMs and their configurations.
2. The specified Talos OS images are downloaded to the Proxmox environment.
3. VMs are created and configured within Proxmox according to the definitions.
4. The `talos_machine_configuration_apply` opentofu resource applies the generated YAML configuration to each Talos
   node.
5. The `talos_machine_bootstrap` opentofu resource bootstraps the Kubernetes cluster on the first control plane node.
6. The `talos_cluster_kubeconfig` opentofu resource retrieves the Kubeconfig file, which is required for accessing the
   newly created Kubernetes cluster.
7. The `talos_cluster_health` data source performs a check to confirm that the cluster has reached a healthy operational
   state.

### Outputs

The opentofu configuration outputs the generated `kubeconfig_raw` (raw Kubeconfig content) and `talos_config` (Talos
client configuration). These outputs, marked as sensitive, facilitate immediate interaction with the Kubernetes cluster
and the Talos API upon completion of the provisioning process. Their definitions can be found in `/tofu/output.tf`.

## Maintain the cluster

### Upgrade Kubernetes or Talos

1. To update versions, modify the relevant parameters in `/tofu/main.tf` (e.g., `image.version`,
   `cluster.talos_version`, `cluster.kubernetes_version`).
2. For nodes that require recreation with the new image or configuration, set their `update` flag to `true` in the node
   definition.
3. Apply the changes using opentofu:

   ```bash
   opentofu apply
   ```

4. Alternatively, for Kubernetes version upgrades on existing Talos nodes, you can use the `/tofu/upgrade-k8s.sh` script
   in conjunction with `talosctl`.

### Add or remove nodes

1. To add or remove nodes, modify the `nodes` map definition within `/tofu/main.tf`.
2. Apply the changes using opentofu:

   ```bash
   opentofu apply
   ```

### Change VM resources

1. To adjust CPU or RAM allocations, modify these parameters in the `nodes` map within `/tofu/main.tf`.
2. Apply the changes using opentofu:

   ```bash
   opentofu apply
   ```

   Proxmox will attempt to update the VM specifications accordingly. Note that resource hot-plug capabilities may vary
   depending on the VM's state and Proxmox configuration.

This opentofu-based setup provides a robust and reproducible method for managing the lifecycle of the Kubernetes
cluster's base infrastructure.
